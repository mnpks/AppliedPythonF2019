{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:58.326022Z",
     "start_time": "2019-10-31T20:50:57.197816Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формальная постановка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T09:44:35.143558Z",
     "start_time": "2019-10-31T09:44:35.139440Z"
    }
   },
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/class1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/class2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан набор обучающих примеров $$(x_1, x_2, \\dots, x_n), x_i \\in \\mathcal{X} \\subseteq \\mathbb{R}^k,$$ $n$ -- размер выборки, $k$ -- количество признаков (фичей). Также задан набор целевых переменных $$(y_1, y_2, \\dots, y_n), y_i \\in \\mathcal{Y} \\subseteq \\mathbb{R}.$$\n",
    "\n",
    "Наша задача построить алгоритм\n",
    "$$a: \\mathcal{X} \\to \\mathcal{Y},$$\n",
    "который будет приближать исходную зависимость $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача классификации\n",
    "Множество $\\mathcal{Y}$ конечно.\n",
    "\n",
    "Частный случай -- бинарная классификация ($|\\mathcal{Y}| = 2$), например, предсказываем будет ли клик, покупка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам надо найти уравнение прямой (гиперплоскости), которая бы могла разделить два класса ($H_2$ и $H_3$ подходят). В данном случае, уравнение прямой задаётся как: $$g(x) = w_0 + w_1x[1] + w_2x[2] = \\langle w, x \\rangle + w_0 =  w^\\top x + w_0$$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = 1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = 0$\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = \n",
    "\\begin{cases}\n",
    "1, &\\text{если } g(x^*) > 0,\\\\\n",
    "0, &\\text{если } g(x^*) < 0.\n",
    "\\end{cases}$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{w_0}{||w||}$ - расстояние от начала координат то прямой\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Значит нам надо просто минимизировать ошибки классификации для всех объектов:\n",
    "\n",
    "$$L(w) = \\sum_{i: y_i = 0} [g(x_i) > 0] + \\sum_{i: y_i = 1} [g(x_i) < 0] \\rightarrow \\min_w$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что это будет комбинаторная оптимизация. Существуют различные аппроксимации этой функции ошибок:\n",
    "<center><img src='http://jaquesgrobler.github.io/Online-Scikit-Learn-stat-tut/_images/plot_sgd_loss_functions_11.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим функцию $$\\sigma(z) = \\frac{1}{1 + exp{(-z)}},$$она называется **сигмойда**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:58.781461Z",
     "start_time": "2019-10-31T20:50:58.329475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_sigmoid():\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "def sigmoid(z): \n",
    "    return 1./(1+np.exp(-z))\n",
    "demo_sigmoid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/prob.png\" style=\"height:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи\n",
    "Будем требовать, чтобы алгоритм возвращал вероятность класса $y=1$:\n",
    "$$h(x,w) = p(y=1|x,w) = \\sigma(g(x))$$\n",
    "\n",
    "Выпишем функцию правдоподобия\n",
    "$$ \\mathcal{L}(w) = \\prod_{i=1}^n h(x_i,w)^{[y_i = 1]} (1 - h(x_i,w))^{[y_i = 0]} \\rightarrow \\max_w$$\n",
    "$$ -\\log{\\mathcal{L}(w)} = - \\sum_i^n [y_i = 1]\\cdot\\log{(h(x_i,w))} + {[y_i = 0]}\\cdot\\log{(1-h(x_i,w))} \\rightarrow \\min_w$$\n",
    "$$L(w) = -\\log{\\mathcal{L}(w)} \\rightarrow \\min_w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм $h$ называется ***логистической регрессией***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из основных функций потерь -- ***Log Loss*** (бинарная классификация), которую мы получили при выводе логрегрессии:\n",
    "$$L = -\\sum_{i=1}^n(\\,\\,y_i \\cdot \\log{a(x_i)} + (1 - y_i) \\cdot \\log(1 - a(x_i))\\,\\,).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случай нескольких классов (>2)\n",
    "\n",
    "* А если классов несколько?\n",
    "    * 1-vs-1\n",
    "    * 1-vs-rest\n",
    "    * Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Для каждого класса определяется свой набор весов\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "g_1(x)=w_{1}^{T}x + w_{0,1} \\\\\n",
    "g_{2}(x)=w_{2}^{T}x + w_{0,2}\\\\\n",
    "\\cdots\\\\\n",
    "g_{C}(x)=w_{C}^{T}x + + w_{0,C}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Нормировка \"скоров\" классов\n",
    "\n",
    "$$\n",
    "p(y=c|x)=softmax(g_c|W, x)=\\frac{exp(w_{c}^{T}x + w_{0,c})}{\\sum_{i}exp(w_{i}^{T}x + w_{0,i})}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cross Entropy Loss*** (общий случай Log Loss), который мы можем вывести по аналогии с Log Loss:\n",
    "$$L = -\\sum_{i=1}^n <y_i , \\log{a(x_i)}>.$$\n",
    "\n",
    "Здесь $y_i$ и $a(x_i)$ -- вектора размерности $|\\mathcal{Y}|$, у $y_i$ только в одной позиции 1, в остальных -- 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод ближайших соседей\n",
    "\n",
    "### K-Nearest Neighbours\n",
    "\n",
    "$$\n",
    "h(x) = \\frac{1}{n} \\sum_{x_j \\in N_K(x)} f(x_j).\n",
    "$$\n",
    "\n",
    "$N_K(\\mathbf{x})$ -- $K$ ближайших соседей для вектора $x$ в обучающем наборе (то есть среди $x_1, ... , x_n$).\n",
    "\n",
    "Как можно использовать для бинарной классификации? А когда классов > 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Байесовский наивный классификатор (Naive Bayes)\n",
    "\n",
    "Дано:\n",
    "\n",
    "$x \\in \\mathcal{X}$ - вектор признаков. Наивность алгоритма характеризуется предположением о том, что компоненты вектора $x$ являются **независимыми** между собой случайными величинами.\n",
    "\n",
    "$C_k \\in \\mathcal{Y}, \\; k = 1,\\ldots,|\\mathcal{Y}|$ - целевая переменная (класс).\n",
    "\n",
    "Теорема Байеса\n",
    "$$\n",
    "P(C_k \\mid x) = \\frac{p(x \\mid C_k) p(C_k)}{p(x)} \\propto p(x \\mid C_k) p(C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из независимости компонент $x$:\n",
    "$$p(x \\mid C_k) = \\prod_j p_j(x[j] \\mid C_k).$$\n",
    "\n",
    "Таким образом обучение состоит в оценке плотностей $p_j(x[j] \\mid C_k), p(C_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание производится с помощью принципа Maximum A-Posteriori:\n",
    "$$\n",
    "C_{MAP} = \\arg \\max_k p(C_k \\mid x) = \\arg \\max_k p(C_k)\\prod_j p_j(x[j] \\mid C_k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовский классификатор — широкий класс алгоритмов классификации, основанный на принципе максимума апостериорной вероятности.  \n",
    "Для классифицируемого объекта вычисляются функции правдоподобия каждого из классов, по ним вычисляются апостериорные вероятности классов.  \n",
    "Объект относится к тому классу, для которого апостериорная вероятность максимальна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "|d | Текст | Класс |\n",
    "|--|--|--|\n",
    "|1 | котики такие мокрые | мимими |\n",
    "|2 | пушистые котики няшки | мимими |\n",
    "|3 | морские котики  | не мимими |\n",
    "|4 | мокрые морские свинки | не мимими |\n",
    "|5 | котики мокрые | ???|\n",
    "\n",
    "С помощью алгоритма MultinomialNB (считаем токены) вычислить $p(\\text{мимими} | d_5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что еще есть: SVM, SVM + kernel trick, Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"images_pt1/prec1.png\" style=\"height:400px\"></td>\n",
    "<td><img src=\"images_pt1/prec2.png\" style=\"height:400px\"></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy = \\frac{1}{n}\\sum_{i=1}^n [a(x_i) = y_i]$$\n",
    "\n",
    "$$Precision = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[a(x_i) = 1]}$$\n",
    "\n",
    "$$Recall = \\sum_{i=1}^n \\frac{[a(x_i) = y_i = 1]}{[y_i = 1]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F мера\n",
    "\n",
    "$$F1 = 2 \\cdot \\frac{Recall \\cdot Precision}{Recall + Precision}.$$\n",
    "\n",
    "$$F_\\beta = (1 + \\beta^2) \\cdot \\frac{Recall \\cdot Precision}{Recall + \\beta^2 \\cdot Precision}.$$\n",
    "\n",
    "$$F_\\beta = \\left({\\frac {\\alpha }{Precision}}+{\\frac {1-\\alpha }{Recall}}\\right)^{-1}, \\,\\,\n",
    "\\alpha ={\\frac {1}{1+\\beta ^{2}}}.$$\n",
    "\n",
    "`Measures the effectiveness of retrieval with respect to a user who attaches β times as much importance to recall as precision.` ([wiki](https://en.wikipedia.org/wiki/F1_score))\n",
    "\n",
    "При $\\beta \\to \\infty$ получаем $F_\\beta \\to Recall$.\n",
    "\n",
    "При $\\beta \\to 0$ получаем $F_\\beta \\to Precision$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "\n",
    "Для задачи бинарной классификации алгоритм $a$ может выдавать не просто метку из $\\mathcal{Y}$, а некоторое число (скор, вероятность). Чтобы сказать какая метка будет на выходе алгоритма используют порог $\\alpha$ так, что:\n",
    "\n",
    "$$\\hat{y}_i =\n",
    "\t \\begin{cases}{}\n",
    "\t \t1, &\\text{если } a(x_i) \\geq \\alpha, \\\\\n",
    "\t \t0, &\\text{если } a(x_i) < \\alpha.\n",
    "\t \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/tp_fp.png\" style=\"height:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В зависимости от этого порога у нас будут получаться разные предсказания на одних и тех же данных. Следовательно и метрики качества, определенные выше, будут разные. Определим следующие величины:\n",
    "\n",
    "$$TPR = \\frac{TP}{TP+FN}, \\,\\, FPR = \\frac{FP}{FP+TN}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разных значений порога $-\\infty < \\alpha < +\\infty$ посчитает значения TPR (True Positive Rate) и FPR (False Positive Rate) и отложим их на графике:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc.png\" style=\"height:400px\">\n",
    "\n",
    "Площадь под графиком и является метрикой ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Интерпретация через непрерывные случайные величины:\n",
    "\n",
    "<img src=\"images_pt1/roc_auc_interpret.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-AUC\n",
    "По аналогии с ROC-AUC, только по осям у нас Precision и Recall.\n",
    "\n",
    "<img src=\"images_pt1/pr_auc.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence (Расстояние Кульбака — Лейблера)\n",
    "\n",
    "$$D_{KL}(P\\parallel Q)=\\sum \\limits _{i=1}^{n}p_{i}\\log {\\frac {p_{i}}{q_{i}}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images_pt1/class3.png\" style=\"height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уравнение прямой задаётся как: $$g(x) = w_0 + w_1x_1 + w_2x_2 = w_0 + \\langle w, x \\rangle = w_0 +  w^\\top x $$\n",
    "\n",
    "* Если $g(x^*) > 0$, то $y^* = \\text{'черный'} = +1$\n",
    "* Если $g(x^*) < 0$, то $y^* = \\text{'белый'} = -1$ (немного поменяем обозначения для простоты изложения)\n",
    "* Если $g(x^*) = 0$, то мы находимся на линии\n",
    "* т.е. решающее правило: $y^* = sign(g(x^*))$\n",
    "\n",
    "Некоторые геометрические особенности\n",
    "* $\\frac{|g(x)|}{||w||}$ - расстояние от точки $x$ до гиперплоскости, степень \"уверенности\" в классификациий\n",
    "* Величину $M = y(\\langle w, x \\rangle + w_0) = y \\cdot g(x)$ называют **отступом**(margin)\n",
    "\n",
    "Если для какого-то объекта $M \\geq 0$, то его классификация выполнена успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Линейноразделимый случай с двумя классами\n",
    "* Заметим что $g(x) = w_0 + \\langle w, x \\rangle$ и $g'(x) = c \\cdot (w_0 + \\langle w, x \\rangle)$, $\\forall c>0$ задают одну и ту же гиперплоскость\n",
    "* Подберем $c$ таким образом, чтобы $\\min\\limits_i M_i = \\min\\limits_i y \\cdot g(x_i) = 1$\n",
    "\n",
    "<center><img src='./images_pt1/margin.png'></center>\n",
    "\n",
    "* Таким образом выполняются следующие неравенства:\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\geq 1$, если $y_i = + 1$\n",
    "    * $w_0 + \\langle w, x_i \\rangle \\leq - 1$, если $y_i = - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Разделяющая полоса:  $ -1 \\leq w_0 + \\langle w, x \\rangle \\leq +1$\n",
    "* Ширина разделяющей полосы:\n",
    " $$\\langle (x_{+} -  x_{-}) , \\frac{w}{||w||}\\rangle = \\frac{\\langle w, x_{+} \\rangle - \\langle w, x_{-} \\rangle }{||w||} = \\frac{2}{||w||}  \\rightarrow \\max$$\n",
    " \n",
    " \n",
    "* Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2  \\rightarrow \\min  \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По теореме Куна-Таккера:\n",
    "\n",
    "\n",
    "$$\\begin{cases} \n",
    "   \\mathcal{L}(w,w_0,\\lambda) = \\frac{1}{2} ||w||^2  - \\sum\\limits_i \\lambda_i \\left( y^{(i)}(\\langle w, x \\rangle + w_0 )  - 1\\right)  \\rightarrow \\min\\limits_{w,w_0}\\max\\limits_{\\lambda}  \\\\\n",
    "   \\lambda_i \\geq 0 \\quad i=1\\dots n\\\\\n",
    "   \\lambda_i = 0 \\text{, либо }  \\langle w, x^{(i)} \\rangle + w_0 = y^{(i)} \\quad i=1\\dots n\n",
    "\\end{cases}$$\n",
    "Объекты, для которых  $\\lambda_i \\neq 0$ называются ** опорными ** \n",
    "\n",
    "\n",
    "Необходимое условие:\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w} = w - \\sum\\limits_i \\lambda_iy_ix_i = 0 \\quad \\Rightarrow  \\quad w = \\sum\\limits_i \\lambda_iy_ix_i$\n",
    "*  $\\frac{\\partial \\mathcal{L} }{\\partial w_0} = \\sum\\limits_i \\lambda_iy_i = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Сопряжённая задача) Если подставить  эти результаты в $\\mathcal{L}$ то получится\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "\\lambda_i \\geq 0 \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "* **Зависит не от самих объектов, а от их скалярного произведения! **\n",
    "* $\\mathcal{L}(\\lambda)$ - выпуклая и ограниченная сверху функция.\n",
    "* Имеем единственное решение при линейной разделимости\n",
    "* Находим $\\lambda_i,$ из $w = \\sum\\limits_i \\lambda_iy_ix_i$ находим коэффициенты $w$.\n",
    "* Свободный член $w_0$ определяется как среднее или медиана $\\{\\langle w, x_i \\rangle - y_i: \\lambda_i \\neq 0\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.547843Z",
     "start_time": "2019-10-31T20:50:58.785859Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print('Так надо')\n",
    "\n",
    "def plot_svc_log_decision_function(clf1, clf2, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    P2 = clf2.decision_function(XY)\n",
    "    P2 = P2.reshape(XX.shape)\n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "    ax.contour(XX, YY, P2, colors='r', label='logreg',\n",
    "               levels=[0], alpha=0.5,\n",
    "               linestyles=['-'])\n",
    "\n",
    "    \n",
    "def plot_svc_decision_function(clf1, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 30)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 30)\n",
    "    XX, YY = np.meshgrid(x, y)\n",
    "    XY = np.c_[XX.ravel(), YY.ravel()]\n",
    "    P1 = clf1.decision_function(XY)\n",
    "    P1 = P1.reshape(XX.shape)\n",
    "    \n",
    "    # plot the margins\n",
    "    cplot = ax.contour(XX, YY, P1, colors='k', label='svm',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    ax.clabel(cplot, inline=1, fontsize=10)\n",
    "    \n",
    "\n",
    "def lin_sep_svm_demo(class_sep=2):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=100).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=100).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    # plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "    #        s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.979482Z",
     "start_time": "2019-10-31T20:50:59.550810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5a4746304d462583c857615a0ed55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.4), Output()), _dom_class…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo(class_sep=2)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo, class_sep=FloatSlider(min=0.4, max=4, step=0.1, value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неразделимый случай \n",
    "\n",
    "Будем допускать пропуск объектов за разделительную линию\n",
    "* Вместо условия $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1$\n",
    "* Будет условие $y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i, \\quad \\xi_i \\geq 0$\n",
    "\n",
    "<center><img src='./images_pt1/slack.png'></center>\n",
    "\n",
    "А целевой функционал заменим на \n",
    "\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом мы придем к оптимизационной задаче:\n",
    "$$\n",
    "\\begin{cases} \n",
    "   \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi} \\\\\n",
    "   y^{(i)}(\\langle w, x^{(i)} \\rangle + w_0 ) \\geq 1 - \\xi_i \\quad i=1\\dots n \\\\\n",
    "   \\xi_i \\geq 0 \\quad i=1\\dots n\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Условия Куна-Таккера, необходимые условия оптимума $\\rightarrow$ получаем сопряженную задачу\n",
    "$$\\begin{cases}\n",
    "\\mathcal{L}(\\lambda) = \\sum\\limits_i\\lambda_i  - \\frac{1}{2} \\sum\\limits_i\\sum\\limits_j \\lambda_i \\lambda_j  y_i y_j (\\langle x_i, x_j \\rangle)  \\rightarrow \\max\\limits_\\lambda  \\\\\n",
    "0 \\leq \\lambda_i \\leq C \\quad i=1\\dots n \\\\\n",
    "\\sum\\limits_i \\lambda_iy_i = 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что изначальный целевой функционал\n",
    "$$ \\frac{1}{2} ||w||^2 + C\\sum\\limits_i\\xi_i  \\rightarrow \\min\\limits_{w,w_0,\\xi}  $$\n",
    "Можно представить в виде\n",
    "$$ \\frac{1}{2С} ||w||^2 + \\sum\\limits_i(1-M_i)_+ \\rightarrow \\min\\limits_{w,w_0}, $$\n",
    "где $M_i$ - это отступ объекта  $x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:50:59.991432Z",
     "start_time": "2019-10-31T20:50:59.983326Z"
    }
   },
   "outputs": [],
   "source": [
    "def lin_sep_svm_demo_C(class_sep=2, C=10):\n",
    "    X, y = make_classification(n_samples=100, n_features=2, n_informative=2, class_sep=class_sep, scale=1,\n",
    "                                n_redundant=0, n_clusters_per_class=1, random_state=31)\n",
    "    # x_line = np.linspace(np.min(X) - 0.5, np.max(X) + 0.5)\n",
    "\n",
    "    lin_svm = SVC(kernel='linear', C=C).fit(X, y)\n",
    "    \n",
    "    log_reg = LogisticRegression(C=C).fit(X, y)\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=70, cmap='autumn')\n",
    "    plot_svc_log_decision_function(lin_svm, log_reg)\n",
    "    plt.scatter(lin_svm.support_vectors_[:, 0], lin_svm.support_vectors_[:, 1],\n",
    "            s=200, facecolors='none')\n",
    "    \n",
    "    \n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    \n",
    "    plt.xlim(-2, 5)\n",
    "    plt.ylim(-3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T20:51:00.305740Z",
     "start_time": "2019-10-31T20:50:59.994494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bb418ad9cf44edbc11872085796e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=2.0, description='class_sep', max=4.0, min=0.2, step=0.2), FloatSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.lin_sep_svm_demo_C(class_sep=2, C=10)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lin_sep_svm_demo_C, class_sep=FloatSlider(min=0.2, max=4, value=2, step=0.2), C=FloatSlider(min=0.002, max=10, step=0.002, value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще есть kernel trick -- делаем преобразование пространства так, что в новом пространстве классы линейно разделимы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
